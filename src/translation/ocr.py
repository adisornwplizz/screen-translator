import cv2
import numpy as np
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from config import OCR_CONFIG, CAPTURE_CONFIG
import base64
import requests
from io import BytesIO
from .ollama_translator import OllamaTranslator


class OCR:
    def __init__(self, engine='tesseract'):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô OCR engine
        engine: 'tesseract' ‡∏´‡∏£‡∏∑‡∏≠ 'ollama_vision' (AI Vision)
        """
        self.engine = engine
        try:
            if self.engine == 'tesseract':
                if os.path.exists(OCR_CONFIG['tesseract_cmd']):
                    pytesseract.pytesseract.tesseract_cmd = OCR_CONFIG['tesseract_cmd']
                else:
                    print("‚ö†Ô∏è  Tesseract ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Tesseract-OCR")
            elif self.engine == 'ollama_vision':
                self.ollama = OllamaTranslator(model='gemma3:4b')
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OCR: {e}")

    def capture_screen(self, region):
        """‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
        
        Args:
            region (tuple): (x, y, width, height)
            
        Returns:
            PIL.Image: ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ
        """
        import pyautogui
        
        try:
            x, y, width, height = region
            screenshot = pyautogui.screenshot(region=(x, y, width, height))
            return screenshot
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û: {e}")
            return None

    def process_image(self, image):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OCR
        
        Args:
            image (PIL.Image): ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            
        Returns:
            PIL.Image: ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
        """
        try:
            if image is None:
                return None
                
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array
            img_array = np.array(image)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale
            if len(img_array.shape) == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î (Contrast Enhancement)
            if CAPTURE_CONFIG['image_processing']['contrast_enhancement']:
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                gray = clahe.apply(gray)
            
            # ‡∏•‡∏î‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏£‡∏ö‡∏Å‡∏ß‡∏ô (Noise Reduction)
            if CAPTURE_CONFIG['image_processing']['noise_reduction']:
                gray = cv2.bilateralFilter(gray, 9, 75, 75)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î (Sharpening)
            if CAPTURE_CONFIG['image_processing']['sharpening']:
                kernel = np.array([[-1,-1,-1],
                                  [-1, 9,-1],
                                  [-1,-1,-1]])
                gray = cv2.filter2D(gray, -1, kernel)
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ threshold
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô PIL Image
            processed_image = Image.fromarray(binary)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û debug (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
            if CAPTURE_CONFIG['save_debug_images']:
                self._save_debug_image(processed_image, "processed")
            
            return processed_image
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û: {e}")
            return image

    def extract_text_ollama_vision(self, image):
        """‡πÉ‡∏ä‡πâ Ollama Vision (gemma3:4b) ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û"""
        try:
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô base64
            buffered = BytesIO()
            image.save(buffered, format="PNG")
            img_b64 = base64.b64encode(buffered.getvalue()).decode()
            prompt = "Read all text in this image. Return only the text, no explanation."
            payload = {
                "model": "gemma3:4b",
                "prompt": prompt,
                "images": [img_b64],
                "stream": False,
                "options": {"temperature": 0.1, "max_tokens": 1024}
            }
            url = f"http://localhost:11434/api/generate"
            response = requests.post(url, json=payload, timeout=60)
            if response.status_code == 200:
                result = response.json()
                text = result.get('response', '').strip()
                return text
            else:
                print(f"‚ùå Ollama Vision error: {response.text}")
                return ""
        except Exception as e:
            print(f"‚ùå Ollama Vision OCR error: {e}")
            return ""

    def extract_text(self, image):
        """‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ engine ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"""
        if self.engine == 'ollama_vision':
            return self.extract_text_ollama_vision(image)
        
        try:
            if image is None:
                return ""
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô
            processed_image = self.process_image(image)
            
            # ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ Tesseract
            config = f"--psm 6 -l {OCR_CONFIG['language']}"
            text = pytesseract.image_to_string(processed_image, config=config)
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            cleaned_text = self._clean_text(text)
            
            return cleaned_text
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {e}")
            return ""

    def get_text_with_confidence(self, image):
        """‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö AI Vision)"""
        if self.engine == 'ollama_vision':
            text = self.extract_text_ollama_vision(image)
            # AI Vision ‡πÑ‡∏°‡πà‡∏°‡∏µ confidence score ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô 0.9 ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, 0 ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
            conf = 0.9 if text.strip() else 0.0
            return text, conf
        
        try:
            if image is None:
                return "", 0
            
            processed_image = self.process_image(image)
            
            # ‡πÉ‡∏ä‡πâ image_to_data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
            config = f"--psm 6 -l {OCR_CONFIG['language']}"
            data = pytesseract.image_to_data(processed_image, config=config, output_type=pytesseract.Output.DICT)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
            confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            words = []
            for i, word in enumerate(data['text']):
                if int(data['conf'][i]) > 30:  # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 30%
                    words.append(word)
            
            text = ' '.join(words)
            cleaned_text = self._clean_text(text)
            
            return cleaned_text, avg_confidence
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {e}")
            return "", 0

    def _clean_text(self, text):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        
        Args:
            text (str): ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏¥‡∏ö
            
        Returns:
            str: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
        """
        if not text:
            return ""
        
        # ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        # ‡∏£‡∏ß‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        cleaned = ' '.join(lines)
        
        # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
        cleaned = ' '.join(cleaned.split())
        
        return cleaned

    def _save_debug_image(self, image, suffix):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö debug
        
        Args:
            image (PIL.Image): ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
            suffix (str): ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        """
        try:
            debug_folder = CAPTURE_CONFIG['debug_folder']
            if not os.path.exists(debug_folder):
                os.makedirs(debug_folder)
            
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"debug_{suffix}_{timestamp}.png"
            filepath = os.path.join(debug_folder, filename)
            
            image.save(filepath)
            print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û debug: {filepath}")
            
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û debug: {e}")

    def test_ocr(self):
        """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á OCR"""
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            from PIL import Image, ImageDraw, ImageFont
            
            img = Image.new('RGB', (400, 200), color='white')
            draw = ImageDraw.Draw(img)
            
            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            test_text = "Hello World!\n‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"
            draw.text((50, 50), test_text, fill='black')
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö OCR
            result = self.extract_text(img)
            confidence = self.get_text_with_confidence(img)[1]
            
            print(f"üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö OCR:")
            print(f"   ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: {test_text}")
            print(f"   ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå OCR: {result}")
            print(f"   ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {confidence:.1f}%")
            
            return result, confidence
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö OCR: {e}")
            return "", 0